"""
Exploitation Agent for PwnAI.

This agent is responsible for developing an exploit based on the vulnerabilities 
identified by the other agents.
"""

import json
import os
import re
import subprocess
import sys
import tempfile
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import pwn
from pwn import *  # Import all pwntools functionality

from pwnai.agents.base_agent import BaseAgent
from pwnai.tools.gdb import GDBWrapper
from pwnai.tools.radare2 import Radare2
from pwnai.utils.llm_service import LLMService


class ExploitationAgent(BaseAgent):
    """
    Agent for developing exploits.
    
    This agent uses information from the Reversing and Debugging Agents
    to develop working exploits for identified vulnerabilities.
    """
    
    def __init__(
        self,
        state: Dict[str, Any],
        binary_path: Path,
        output_dir: Path,
        llm_config: Optional[Dict[str, Any]] = None,
        llm_service: Optional[LLMService] = None,
        remote_host: Optional[str] = None,
        remote_port: Optional[int] = None,
    ):
        """
        Initialize the Exploitation Agent.
        
        Args:
            state: Shared state dictionary for inter-agent communication
            binary_path: Path to the target binary
            output_dir: Directory to store output files
            llm_config: Configuration for the LLM
            llm_service: Optional shared LLM service instance
            remote_host: Remote host for the challenge (if applicable)
            remote_port: Remote port for the challenge (if applicable)
        """
        super().__init__(state, binary_path, output_dir, llm_config, llm_service)
        
        self.remote_host = remote_host
        self.remote_port = remote_port
        
        # Initialize binary analyzer
        self.binary_analyzer = Radare2(str(binary_path))
        
        # Initialize GDB wrapper for testing exploits
        self.gdb = GDBWrapper(binary_path)
        
        # Set architecture for pwntools context
        if "architecture" in self.state:
            arch_info = self.state["architecture"]
            if arch_info.get("arch") == "x86" and arch_info.get("bits") == 64:
                context.arch = "amd64"
            elif arch_info.get("arch") == "x86" and arch_info.get("bits") == 32:
                context.arch = "i386"
            elif arch_info.get("arch") == "arm" and arch_info.get("bits") == 64:
                context.arch = "aarch64"
            elif arch_info.get("arch") == "arm":
                context.arch = "arm"
        
        # Set binary for pwntools context
        context.binary = self.binary_path
        
        # Initialize LLM service if not provided
        if self.llm_service is None:
            llm_system_prompt = """
            You are a binary exploitation expert tasked with developing exploits for CTF challenges.
            You have deep knowledge of exploitation techniques including buffer overflows, format string attacks,
            ROP chains, return-to-libc, and other memory corruption techniques.
            
            Based on the information provided about the target binary (vulnerabilities, memory layout,
            security features, etc.), your task is to develop a working exploit. You should:
            
            1. Select the appropriate exploitation technique based on the vulnerability and security features
            2. Craft a precise payload with the correct offsets, addresses, and ROP gadgets
            3. Utilize pwntools functions to create and test the exploit
            4. Generate a Python script that implements the exploit
            
            Your exploit script should be well-commented, explaining each step of the exploitation process.
            The script should work both locally and against a remote target when available.
            """
            
            self.llm = LLMService(
                system_prompt=llm_system_prompt,
                **(llm_config or {})
            )
        else:
            self.llm = self.llm_service
    
    def run(self, remote: bool = False) -> Dict[str, Any]:
        """
        Run the exploitation agent to develop and test an exploit.
        
        Args:
            remote: If True, attempt to exploit a remote target
            
        Returns:
            Updated state dictionary with the exploitation results
        """
        self.logger.info("Starting exploitation process")
        
        # If targeting a remote server
        if remote:
            self.logger.info(f"Targeting remote server: {self.state.get('remote_target')}")
            return self._run_remote_exploit()
        
        # Extract vulnerabilities identified in previous stages
        vulnerabilities = self.state.get("vulnerabilities", [])
        
        # Extract debugging results
        debug_results = {}
        for key in ["overflow_offset", "gadgets", "leaked_addresses"]:
            if key in self.state:
                debug_results[key] = self.state[key]
        
        # 1. Plan the exploitation
        self.logger.debug("Planning exploitation approach")
        exploitation_plan = self._create_exploitation_plan()
        
        # Track our exploit attempts for iterative refinement
        MAX_ITERATIONS = 3  # Maximum number of refinement iterations
        iteration = 0
        success = False
        result_data = {}
        
        # Iterative exploit development process
        while iteration < MAX_ITERATIONS and not success:
            iteration += 1
            self.logger.info(f"Starting exploit development iteration {iteration}/{MAX_ITERATIONS}")
            
            # 2. Develop the exploit
            if iteration == 1:
                self.logger.info("Developing initial exploit")
                exploit_code, exploit_description = self._develop_exploit(exploitation_plan)
            else:
                self.logger.info(f"Refining exploit based on previous failure (iteration {iteration})")
                exploit_code, exploit_description = self._refine_exploit(exploitation_plan, failure_data)
            
            # 3. Test the exploit
            self.logger.info("Testing exploit against local binary")
            success, result, output = self._test_exploit()
            
            if success:
                self.logger.info("Exploit executed successfully!")
                result_data = result
                break
            else:
                self.logger.warning(f"Exploit failed on iteration {iteration}")
                # Collect failure data
                failure_data = {
                    "output": output,
                    "iteration": iteration,
                    "exploit_code": exploit_code
                }
                
                # Analyze the failure
                failure_analysis = self._analyze_failure(failure_data)
                
                # Log the failure analysis
                self.logger.info(f"Failure analysis: {failure_analysis.get('summary', 'Unknown error')}")
                
                # Update the exploitation plan with the failure insights
                exploitation_plan = self._update_exploitation_plan(exploitation_plan, failure_analysis)
                
                # Save the improved plan
                plan_path = self.output_dir / f"exploitation_plan_iteration_{iteration+1}.txt"
                with open(plan_path, "w") as f:
                    f.write(exploitation_plan)
        
        # If all iterations failed, log the best attempt
        if not success:
            self.logger.error(f"Failed to develop a working exploit after {MAX_ITERATIONS} iterations")
            result_data = {"exploitable": False, "reason": "Maximum iterations reached without success"}
        
        # Return the results as state updates
        results = {
            "exploit_code": exploit_code,
            "exploit_description": exploit_description,
            "exploitation_plan": exploitation_plan,
            "exploit_successful": success,
        }
        results.update(result_data)
        
        self.logger.info(f"Exploitation completed (success: {success})")
        return results
    
    def _create_exploitation_plan(self) -> str:
        """
        Create an exploitation plan based on the findings.
        
        Returns:
            Exploitation plan as a string
        """
        # Get relevant information from the state
        vuln_type = self.state.get("vulnerability_type", "unknown")
        vulnerabilities = self.state.get("vulnerabilities", [])
        
        # Security features
        security_features = self.state.get("security_features", {})
        
        # Debugging results
        overflow_offset = self.state.get("overflow_offset")
        gadgets = self.state.get("gadgets", [])
        leaked_addresses = self.state.get("leaked_addresses", {})
        
        # Build a prompt for the LLM
        prompt = f"""
        I need to develop an exploitation plan for a binary with a {vuln_type} vulnerability.
        
        ## Security Features
        - NX (No-Execute): {security_features.get('nx', 'unknown')}
        - Stack Canary: {security_features.get('canary', 'unknown')}
        - PIE (Position Independent Executable): {security_features.get('pie', 'unknown')}
        - RELRO: {security_features.get('relro', 'unknown')}
        
        ## Debugging Results
        - Overflow Offset: {overflow_offset}
        - Number of Gadgets: {len(gadgets)}
        - Leaked Addresses: {leaked_addresses}
        
        ## Vulnerabilities
        {self._format_vulnerabilities(vulnerabilities)}
        
        Based on this information, create a detailed exploitation plan. 
        Include the specific techniques you'll use, any gadgets needed, 
        and how you'll bypass security features.
        
        Provide instructions for developing the exploit that would achieve 
        the goal of the challenge, which typically involves getting a shell, 
        reading a flag file, or triggering a specific condition.
        """
        
        # Incorporate user feedback if available
        prompt = self.incorporate_feedback(prompt)
        
        # Incorporate source file if available
        prompt = self.incorporate_source(prompt)
        
        # If we have specific vulnerabilities, incorporate the feedback from the first one
        if vulnerabilities and isinstance(vulnerabilities[0], dict):
            prompt = self.incorporate_vulnerability_feedback(prompt, vulnerabilities[0])
        
        # Call LLM
        self.logger.info("Creating exploitation plan...")
        plan = self.llm.call(prompt)
        
        # Save plan to file
        plan_path = self.output_dir / "exploitation_plan.txt"
        with open(plan_path, "w") as f:
            f.write(plan)
        
        self.logger.info(f"Saved exploitation plan to {plan_path}")
        
        return plan
    
    def _format_vulnerabilities(self, vulnerabilities: List[Dict[str, Any]]) -> str:
        """
        Format vulnerabilities for inclusion in prompts.
        
        Args:
            vulnerabilities: List of vulnerability dictionaries
            
        Returns:
            Formatted string describing vulnerabilities
        """
        if not vulnerabilities:
            return "No specific vulnerabilities identified."
            
        formatted_text = ""
        for i, vuln in enumerate(vulnerabilities):
            vuln_type = vuln.get("type", "Unknown")
            formatted_text += f"{i+1}. Type: {vuln_type}\n"
            
            for field in ["location", "description", "exploitation", "constraints"]:
                if field in vuln:
                    formatted_text += f"   {field.capitalize()}: {vuln[field]}\n"
            
            formatted_text += "\n"
            
        return formatted_text
    
    def _develop_exploit(self, exploitation_plan: str) -> Tuple[str, str]:
        """
        Develop an exploit based on the exploitation plan.
        
        Args:
            exploitation_plan: The exploitation plan to follow
            
        Returns:
            Tuple of (exploit code, exploit description)
        """
        # Get debugging results needed for exploitation
        overflow_offset = self.state.get("overflow_offset")
        gadgets = self.state.get("gadgets", [])
        leaked_addresses = self.state.get("leaked_addresses", {})
        security_features = self.state.get("security_features", {})
        
        # Get binary path - use absolute path to prevent file not found errors
        binary_path = str(self.binary_path.resolve())
        binary_name = os.path.basename(binary_path)
        
        # Format gadgets for the prompt
        gadgets_text = ""
        for i, gadget in enumerate(gadgets[:10]):  # Limit to top 10 gadgets
            addr = gadget.get("address", "unknown")
            instr = gadget.get("instruction", "unknown")
            gadgets_text += f"- `{instr}` at address {addr}\n"
        
        if len(gadgets) > 10:
            gadgets_text += f"... and {len(gadgets) - 10} more gadgets\n"
            
        # Create prompt for the LLM
        prompt = f"""
        Please develop a Python exploit script using pwntools for the vulnerability described in the exploitation plan.
        
        ## EXPLOITATION PLAN
        {exploitation_plan}
        
        ## BINARY INFORMATION
        - Binary absolute path: {binary_path}
        - Binary name: {binary_name}
        
        ## DEBUGGING INFORMATION
        - Buffer Overflow Offset: {overflow_offset if overflow_offset is not None else "Not determined"}
        - Security Features:
          - NX: {security_features.get("nx", "unknown")}
          - Canary: {security_features.get("canary", "unknown")}
          - PIE: {security_features.get("pie", "unknown")}
          - RELRO: {security_features.get("relro", "unknown")}
        - Available Gadgets:
        {gadgets_text}
        - Leaked Addresses: {leaked_addresses}
        
        Create a complete, well-commented Python exploit script that implements the exploitation plan.
        Use pwntools functions like p64(), p32(), log.info(), etc. as needed.
        The script should work both locally and against a remote target.
        
        IMPORTANT: Your exploit needs to work in both interactive and automated testing modes. For automated testing, 
        the script shouldn't call io.interactive() unconditionally, as this will cause the automated tester to hang.
        
        Use the following template to structure your exploit:
        
        ```python
        #!/usr/bin/env python3
        from pwn import *
        import sys
        
        # Set up context for architecture
        context.binary = "{binary_path}"  # IMPORTANT: Use this exact binary path
        
        # Define exploit function
        def exploit(target, automatic_mode=False):
            # Connect to target
            io = target
            
            # [Your exploit code here]
            
            # For automated testing, check if we got a shell or the flag without using interactive()
            if automatic_mode:
                # Try to execute a command to verify we have a shell, or check for flag
                # For example, if we have a shell:
                io.sendline(b"echo pwned")
                result = io.recvline_contains(b"pwned", timeout=2)
                if result:
                    log.success("Exploit successful!")
                    return True
                else:
                    log.error("Exploit failed")
                    return False
            else:
                # Only call interactive in manual mode
                log.success("Switching to interactive mode...")
                io.interactive()
        
        if __name__ == "__main__":
            # Set up logging
            context.log_level = 'info'
            
            # Check if running in automatic testing mode
            automatic_mode = "--automatic" in sys.argv
            
            # Local exploitation - IMPORTANT: Use the absolute path to the binary
            binary_path = "{binary_path}"  # This must be the absolute path
            log.info(f"Exploiting binary at {{binary_path}}")
            
            # Run exploit
            if "--remote" in sys.argv and len(sys.argv) > 2:
                host, port = sys.argv[2].split(":")
                log.info(f"Exploiting remotely at {{host}}:{{port}}")
                target = remote(host, int(port))
                result = exploit(target, automatic_mode)
                if automatic_mode and result:
                    print("EXPLOIT_SUCCESS")
            else:
                log.info("Exploiting locally")
                target = process([binary_path])
                result = exploit(target, automatic_mode)
                if automatic_mode and result:
                    print("EXPLOIT_SUCCESS")
        ```
        
        Make sure to replace placeholder values with actual values from the debugging information.
        Include detailed comments explaining each step of the exploit.
        IMPORTANT: Do NOT use placeholder paths like './vulnerable_binary'. Use the exact path I provided.
        CRITICAL: Make sure the automatic_mode code works to verify if the exploit was successful without user interaction.
        """
        
        # Add source code information if available
        source_code = self.read_source_file()
        if source_code:
            source_section = f"""
        ## SOURCE CODE
        ```c
        {source_code}
        ```
        
        Use the source code to identify specific vulnerabilities and craft a more precise exploit.
        """
            prompt = prompt.replace("## DEBUGGING INFORMATION", source_section + "\n## DEBUGGING INFORMATION")
        
        # Add user feedback if available
        prompt = self.incorporate_feedback(prompt)
        
        # Call LLM
        self.logger.info("Generating exploit code...")
        response = self.llm.call(prompt)
        
        # Extract the code and description
        exploit_code = ""
        description = ""
        
        # Parse the response to extract just the code
        if "```python" in response:
            parts = response.split("```python", 1)
            description = parts[0].strip()
            if "```" in parts[1]:
                code_part = parts[1].split("```", 1)[0]
                exploit_code = code_part.strip()
            else:
                exploit_code = parts[1].strip()
        elif "```" in response:
            parts = response.split("```", 2)
            if len(parts) >= 3:
                description = parts[0].strip()
                exploit_code = parts[1].strip()
                if not description and len(parts) > 2:
                    description = parts[2].strip()
            else:
                exploit_code = response
        else:
            exploit_code = response
        
        # Process the code to ensure binary paths are correct
        exploit_code = exploit_code.replace("./vulnerable_binary", binary_path)
        exploit_code = exploit_code.replace("./binary_name", binary_path)
        
        # Save exploit to file
        exploit_path = self.output_dir / "exploit.py"
        with open(exploit_path, "w") as f:
            f.write(exploit_code)
            
        self.logger.info(f"Saved exploit to {exploit_path}")
        
        # Make the exploit executable
        os.chmod(exploit_path, 0o755)
        
        return exploit_code, description
    
    def _extract_code(self, response: str) -> str:
        """
        Extract Python code from an LLM response.
        
        Args:
            response: The LLM response text
            
        Returns:
            The extracted Python code
        """
        # Look for Python code blocks
        python_blocks = re.findall(r'```(?:python)?\s*\n(.*?)```', response, re.DOTALL)
        
        if python_blocks:
            # Use the longest code block (most likely the full script)
            code = max(python_blocks, key=len)
        else:
            # If no code blocks found, try to extract all the script
            # by looking for common Python syntax
            potential_script = ""
            in_script = False
            
            for line in response.split('\n'):
                if not in_script and (line.startswith('from ') or line.startswith('import ') or 
                                    line.startswith('#!/usr/bin/env python')):
                    in_script = True
                    potential_script += line + '\n'
                elif in_script:
                    potential_script += line + '\n'
            
            if potential_script:
                code = potential_script
            else:
                # As a fallback, just return the entire response
                code = response
        
        # Fix common issues in the generated code
        # Fix incorrect process() calls
        code = re.sub(
            r'process\s*\(\s*context\.binary\s*\)', 
            r'process([context.binary.path])', 
            code
        )
        code = re.sub(
            r'process\s*\(\s*[\'"](.+?)[\'"]\s*\)', 
            r'process([\1])', 
            code
        )
        
        return code
    
    def _test_exploit(self) -> Tuple[bool, Dict[str, Any], str]:
        """
        Test the exploit script locally.
        
        Returns:
            Tuple of (success boolean, result dictionary, output text)
        """
        self.logger.info("Testing exploit script locally")
        
        # Check if the exploit script exists
        exploit_path = self.output_dir / "exploit.py"
        if not os.path.exists(exploit_path):
            self.logger.error(f"Exploit script not found at {exploit_path}")
            return False, {}, f"Error: Exploit script not found at {exploit_path}"
        
        try:
            # Set up environment variables
            env = os.environ.copy()
            env["TERM"] = "xterm-256color"  # Set a standard terminal type
            env["PWNLIB_NOTERM"] = "true"  # Disable terminal features that might cause issues
            
            # Run the exploit in automatic testing mode
            cmd = [sys.executable, str(exploit_path), "--automatic"]
            if self.remote_host and self.remote_port:
                # If testing locally, add --local flag if script supports it
                cmd.extend(["--remote", f"{self.remote_host}:{self.remote_port}"])
            
            self.logger.debug(f"Running command: {' '.join(cmd)}")
            
            # Run with a timeout
            proc = subprocess.run(
                cmd,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=30  # 30 second timeout for exploit
            )
            
            # Capture the output
            output = proc.stdout + "\n" + proc.stderr
            
            # Check for success indicators in output
            success_indicators = ["EXPLOIT_SUCCESS", "pwned", "shell", "success", "flag{", "CTF{", "FLAG{"]
            success = any(indicator.lower() in output.lower() for indicator in success_indicators)
            
            # If the exploit seems to have succeeded but returned non-zero, warn but don't fail
            if proc.returncode != 0:
                self.logger.warning(f"Exploit test returned code {proc.returncode}, may not be successful")
            
            # Parse the output to extract result data
            result = {}
            for indicator in success_indicators:
                if indicator.lower() in output.lower():
                    result[indicator.replace("{", "").replace("}", "").replace("CTF", "").replace("flag", "").replace("pwned", "").replace("shell", "").replace("success", "")] = True
            
            return success, result, output
        
        except subprocess.TimeoutExpired:
            self.logger.warning("Exploit test timed out")
            return False, {}, "Timeout: Exploit test took too long to complete"
        
        except Exception as e:
            self.logger.error(f"Error testing exploit: {str(e)}")
            return False, {}, f"Error: {str(e)}"
    
    def _analyze_failure(self, failure_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze why an exploit attempt failed.
        
        Args:
            failure_data: Data about the failed exploit attempt including output and code
            
        Returns:
            Dictionary with analysis results including potential fixes
        """
        output = failure_data.get("output", "")
        exploit_code = failure_data.get("exploit_code", "")
        iteration = failure_data.get("iteration", 0)
        
        self.logger.info(f"Analyzing failure from iteration {iteration}")
        
        # Create a prompt for LLM to analyze the failure
        prompt = f"""
        I'm trying to develop an exploit for a binary, but my exploit attempt failed.
        Please analyze the exploit code and the program output to determine why it failed
        and suggest specific changes to fix the issues.
        
        ## EXPLOIT CODE
        ```python
        {exploit_code}
        ```
        
        ## PROGRAM OUTPUT
        ```
        {output}
        ```
        
        Based on this information, please:
        1. Identify the specific reason(s) for failure
        2. Suggest precise fixes/changes to the exploit code
        3. Explain any conceptual misunderstandings or incorrect assumptions in the exploit
        
        Return your analysis in this format:
        ```
        FAILURE_REASON: [Brief description of why the exploit failed]
        ISSUES:
        - [Issue 1]
        - [Issue 2]
        ...
        PROPOSED_FIXES:
        - [Fix 1]
        - [Fix 2]
        ...
        EXPLANATION: [Detailed explanation of what went wrong and how the fixes address the issues]
        ```
        """
        
        # Incorporate source file if available
        prompt = self.incorporate_source(prompt)
        
        # Call LLM
        self.logger.debug("Sending failure analysis request to LLM")
        response = self.llm.call(prompt)
        
        # Parse the response to extract structured information
        analysis = self._parse_failure_analysis(response)
        
        # Save the analysis to a file
        analysis_path = self.output_dir / f"failure_analysis_iteration_{iteration}.txt"
        with open(analysis_path, "w") as f:
            f.write(response)
        
        self.logger.info(f"Saved failure analysis to {analysis_path}")
        
        return analysis
    
    def _parse_failure_analysis(self, response: str) -> Dict[str, Any]:
        """
        Parse the LLM's failure analysis response into a structured format.
        
        Args:
            response: The LLM's analysis text
            
        Returns:
            Dictionary with structured failure analysis
        """
        analysis = {
            "failure_reason": "",
            "issues": [],
            "proposed_fixes": [],
            "explanation": "",
            "summary": "",
            "full_analysis": response
        }
        
        # Extract failure reason
        if "FAILURE_REASON:" in response:
            parts = response.split("FAILURE_REASON:", 1)
            reason_part = parts[1].split("\n", 1)[0].strip()
            analysis["failure_reason"] = reason_part
            analysis["summary"] = reason_part
        
        # Extract issues
        if "ISSUES:" in response:
            parts = response.split("ISSUES:", 1)
            issues_part = parts[1].split("PROPOSED_FIXES:" if "PROPOSED_FIXES:" in parts[1] else "EXPLANATION:", 1)[0]
            issues = []
            for line in issues_part.strip().split("\n"):
                if line.strip().startswith("-"):
                    issues.append(line.strip()[1:].strip())
            analysis["issues"] = issues
        
        # Extract proposed fixes
        if "PROPOSED_FIXES:" in response:
            parts = response.split("PROPOSED_FIXES:", 1)
            fixes_part = parts[1].split("EXPLANATION:" if "EXPLANATION:" in parts[1] else "\n\n", 1)[0]
            fixes = []
            for line in fixes_part.strip().split("\n"):
                if line.strip().startswith("-"):
                    fixes.append(line.strip()[1:].strip())
            analysis["proposed_fixes"] = fixes
        
        # Extract explanation
        if "EXPLANATION:" in response:
            parts = response.split("EXPLANATION:", 1)
            explanation = parts[1].strip()
            analysis["explanation"] = explanation
        
        return analysis
    
    def _refine_exploit(self, exploitation_plan: str, failure_data: Dict[str, Any]) -> Tuple[str, str]:
        """
        Refine an exploit based on failure analysis.
        
        Args:
            exploitation_plan: The current exploitation plan
            failure_data: Data about the failed exploit attempt
            
        Returns:
            Tuple of (refined exploit code, description)
        """
        # Analyze the failure if not already done
        if "analysis" not in failure_data:
            failure_analysis = self._analyze_failure(failure_data)
        else:
            failure_analysis = failure_data["analysis"]
        
        # Extract key information
        previous_code = failure_data.get("exploit_code", "")
        issues = failure_analysis.get("issues", [])
        proposed_fixes = failure_analysis.get("proposed_fixes", [])
        failure_reason = failure_analysis.get("failure_reason", "Unknown failure")
        
        # Create a prompt for LLM to refine the exploit
        prompt = f"""
        I need to refine an exploit that failed. Please create an improved version 
        based on the failure analysis and proposed fixes.
        
        ## PREVIOUS EXPLOIT CODE
        ```python
        {previous_code}
        ```
        
        ## FAILURE ANALYSIS
        Failure reason: {failure_reason}
        
        Issues identified:
        {chr(10).join(['- ' + issue for issue in issues])}
        
        Proposed fixes:
        {chr(10).join(['- ' + fix for fix in proposed_fixes])}
        
        ## EXPLOITATION PLAN
        {exploitation_plan}
        
        Please create a completely new, refined exploit that addresses all the issues 
        identified in the failure analysis. Make sure the exploit follows the general 
        approach outlined in the exploitation plan, but incorporates the necessary 
        fixes to overcome the failure.
        
        Write a complete, executable Python script using pwntools. Include detailed 
        comments explaining your changes and how they address the previous issues.
        """
        
        # Incorporate source file if available
        prompt = self.incorporate_source(prompt)
        
        # Call LLM
        self.logger.info("Generating refined exploit")
        response = self.llm.call(prompt)
        
        # Extract the code and description
        exploit_code = ""
        description = ""
        
        # Parse the response to extract just the code
        if "```python" in response:
            parts = response.split("```python", 1)
            description = parts[0].strip()
            if "```" in parts[1]:
                code_part = parts[1].split("```", 1)[0]
                exploit_code = code_part.strip()
            else:
                exploit_code = parts[1].strip()
        elif "```" in response:
            parts = response.split("```", 2)
            if len(parts) >= 3:
                description = parts[0].strip()
                exploit_code = parts[1].strip()
                if not description and len(parts) > 2:
                    description = parts[2].strip()
            else:
                exploit_code = response
        else:
            exploit_code = response
        
        # Save exploit to file
        exploit_path = self.output_dir / "exploit.py"
        with open(exploit_path, "w") as f:
            f.write(exploit_code)
            
        # Save the iteration-specific copy
        iteration = failure_data.get("iteration", 0) + 1
        iteration_path = self.output_dir / f"exploit_iteration_{iteration}.py"
        with open(iteration_path, "w") as f:
            f.write(exploit_code)
            
        self.logger.info(f"Saved refined exploit to {exploit_path} and {iteration_path}")
        
        # Make the exploit executable
        os.chmod(exploit_path, 0o755)
        
        return exploit_code, description
    
    def _update_exploitation_plan(self, exploitation_plan: str, failure_analysis: Dict[str, Any]) -> str:
        """
        Update the exploitation plan based on failure analysis.
        
        Args:
            exploitation_plan: The current exploitation plan
            failure_analysis: The analysis of the exploit failure
            
        Returns:
            Updated exploitation plan
        """
        # Extract key information from failure analysis
        failure_reason = failure_analysis.get("failure_reason", "Unknown failure")
        issues = failure_analysis.get("issues", [])
        proposed_fixes = failure_analysis.get("proposed_fixes", [])
        explanation = failure_analysis.get("explanation", "")
        
        # Create a prompt for LLM to update the plan
        prompt = f"""
        I need to update an exploitation plan based on failure analysis.
        
        ## CURRENT EXPLOITATION PLAN
        {exploitation_plan}
        
        ## FAILURE ANALYSIS
        Failure reason: {failure_reason}
        
        Issues identified:
        {chr(10).join(['- ' + issue for issue in issues])}
        
        Proposed fixes:
        {chr(10).join(['- ' + fix for fix in proposed_fixes])}
        
        Explanation: {explanation}
        
        Please revise the exploitation plan to address the issues identified in the failure analysis.
        The updated plan should incorporate the lessons learned from the failed attempt and provide
        clearer guidance on how to develop a successful exploit.
        
        Keep the fundamental approach if it's still valid, but adjust any incorrect assumptions,
        add missing details, and correct any technical inaccuracies.
        
        Return a complete, updated exploitation plan that can be used to guide the next exploit attempt.
        """
        
        # Call LLM
        self.logger.info("Updating exploitation plan based on failure analysis")
        updated_plan = self.llm.call(prompt)
        
        return updated_plan
    
    def _run_remote_exploit(self) -> Dict[str, Any]:
        """
        Run the developed exploit against a remote target.
        
        Returns:
            Dictionary with the remote exploitation results
        """
        self.logger.info("Attempting remote exploitation")
        
        # Check if we have a remote target specified
        remote_target = self.state.get("remote_target")
        if not remote_target:
            self.logger.error("No remote target specified")
            return {"exploit_successful": False, "error": "No remote target specified"}
        
        # Parse the remote target
        try:
            host, port_str = remote_target.split(":")
            port = int(port_str)
        except ValueError:
            self.logger.error(f"Invalid remote target format: {remote_target}")
            return {"exploit_successful": False, "error": "Invalid remote target format"}
        
        # Check if we have an exploit script
        exploit_path = self.output_dir / "exploit.py"
        if not exploit_path.exists():
            self.logger.error("No exploit script found")
            return {"exploit_successful": False, "error": "No exploit script found"}
        
        try:
            # Run the exploit with REMOTE=1 environment variable
            env = os.environ.copy()
            env["REMOTE"] = "1"
            env["HOST"] = host
            env["PORT"] = str(port)
            env["PWNLIB_NOTERM"] = "true"  # Disable terminal features
            
            cmd = [sys.executable, str(exploit_path), "--remote", f"{host}:{port}"]
            
            self.logger.info(f"Running command: {' '.join(cmd)}")
            
            # Run with timeout
            proc = subprocess.run(
                cmd,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=60  # 60 second timeout for remote exploitation
            )
            
            output = proc.stdout + "\n" + proc.stderr
            
            # Save the remote output
            remote_output_path = self.output_dir / "remote_exploitation_output.txt"
            with open(remote_output_path, "w") as f:
                f.write(output)
            
            # Check for success indicators
            success_indicators = ["flag{", "CTF{", "pwned", "shell", "success", "FLAG{"]
            success = any(indicator.lower() in output.lower() for indicator in success_indicators)
            
            # Try to extract the flag if successful
            flag = None
            if success:
                # Look for flag pattern
                flag_pattern = re.compile(r'(flag|FLAG|ctf|CTF)\{[^}]+\}')
                flag_match = flag_pattern.search(output)
                if flag_match:
                    flag = flag_match.group(0)
            
            self.logger.info(f"Remote exploitation {'successful' if success else 'failed'}")
            
            return {
                "exploit_successful": success,
                "flag": flag,
                "remote_output": output[:1000]  # Truncate very long output
            }
            
        except subprocess.TimeoutExpired:
            self.logger.warning("Remote exploitation timed out")
            return {"exploit_successful": False, "error": "Timeout during remote exploitation"}
            
        except Exception as e:
            self.logger.error(f"Error during remote exploitation: {str(e)}")
            return {"exploit_successful": False, "error": str(e)} 